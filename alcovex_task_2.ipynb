{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10hoMNQwAUbDR6jfVybZSVVLRu7XA9f5S",
      "authorship_tag": "ABX9TyO7cRuOH4FDTEfLowkAw1Yl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChandanaPulikanti/Data-files/blob/main/alcovex_task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "np.random.seed(2)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import os\n",
        "import itertools\n",
        "\n",
        "def convert_to_ela_image(path, quality):\n",
        "    temp_filename = 'temp_file_name.jpg'\n",
        "    ela_filename = 'temp_ela.png'\n",
        "    \n",
        "    image = Image.open(path).convert('RGB')\n",
        "    image.save(temp_filename, 'JPEG', quality = quality)\n",
        "    temp_image = Image.open(temp_filename)\n",
        "    \n",
        "    ela_image = ImageChops.difference(image, temp_image)\n",
        "    \n",
        "    extrema = ela_image.getextrema()\n",
        "    max_diff = max([ex[1] for ex in extrema])\n",
        "    if max_diff == 0:\n",
        "        max_diff = 1\n",
        "    scale = 255.0 / max_diff\n",
        "    \n",
        "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
        "    \n",
        "    return ela_image\n",
        "\n",
        "!unzip -uq \"/content/drive/MyDrive/Classroom/Dataset_Real_vs_Fake_image_BinaryClassifier.zip\" -d \"/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier\"\n",
        "\n",
        "real_image_path = '/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier'\n",
        "Image.open(real_image_path)\n",
        "\n",
        "convert_to_ela_image(real_image_path, 90)\n",
        "\n",
        "fake_image_path = '/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier'\n",
        "Image.open(fake_image_path)\n",
        "\n",
        "convert_to_ela_image(fake_image_path, 90)\n",
        "\n",
        "image_size = (128, 128)\n",
        "\n",
        "def prepare_image(image_path):\n",
        "    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0\n",
        "\n",
        "X = [] # ELA converted images\n",
        "Y = [] # 0 for fake, 1 for real\n",
        "\n",
        "import random\n",
        "path = '/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier'\n",
        "for dirname, _, filenames in os.walk(path):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('jpg') or filename.endswith('png'):\n",
        "            full_path = os.path.join(dirname, filename)\n",
        "            X.append(prepare_image(full_path))\n",
        "            Y.append(1)\n",
        "            if len(Y) % 500 == 0:\n",
        "                print(f'Processing {len(Y)} images')\n",
        "\n",
        "random.shuffle(X)\n",
        "X = X[:2100]\n",
        "Y = Y[:2100]\n",
        "print(len(X), len(Y))\n",
        "\n",
        "path = '/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier'\n",
        "for dirname, _, filenames in os.walk(path):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('jpg') or filename.endswith('png'):\n",
        "            full_path = os.path.join(dirname, filename)\n",
        "            X.append(prepare_image(full_path))\n",
        "            Y.append(0)\n",
        "            if len(Y) % 500 == 0:\n",
        "                print(f'Processing {len(Y)} images')\n",
        "\n",
        "print(len(X), len(Y))\n",
        "\n",
        "X = np.array(X)\n",
        "Y = to_categorical(Y, 2)\n",
        "X = X.reshape(-1, 128, 128, 3)\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y)\n",
        "X = X.reshape(-1,1,1,1)\n",
        "print(len(X_train), len(Y_train))\n",
        "print(len(X_val), len(Y_val))\n",
        "\n",
        "#CNN Model\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n",
        "    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n",
        "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation = 'softmax'))\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "init_lr = 1e-4\n",
        "optimizer = Adam(lr = init_lr, decay = init_lr/epochs)\n",
        "\n",
        "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor = 'val_acc',\n",
        "                              min_delta = 0,\n",
        "                              patience = 2,\n",
        "                              verbose = 0,\n",
        "                              mode = 'auto')\n",
        "\n",
        "hist = model.fit(X_train,\n",
        "                 Y_train,\n",
        "                 batch_size = batch_size,\n",
        "                 epochs = epochs,\n",
        "                validation_data = (X_val, Y_val),\n",
        "                callbacks = [early_stopping])\n",
        "\n",
        "model.save('model_casia_run1.h5')\n",
        "\n",
        "# Plot the loss and accuracy curves for training and validation \n",
        "fig, ax = plt.subplots(2,1)\n",
        "ax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(X_val)\n",
        "# Convert predictions classes to one hot vectors \n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(Y_val,axis = 1) \n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(2))\n",
        "\n",
        "class_names = ['fake', 'real']\n",
        "\n",
        "real_image_path = '/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier'\n",
        "image = prepare_image(real_image_path)\n",
        "image = image.reshape(-1, 128, 128, 3)\n",
        "y_pred = model.predict(image)\n",
        "y_pred_class = np.argmax(y_pred, axis = 1)[0]\n",
        "print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n",
        "\n",
        "fake_image_path = '/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier'\n",
        "image = prepare_image(fake_image_path)\n",
        "image = image.reshape(-1, 128, 128, 3)\n",
        "y_pred = model.predict(image)\n",
        "y_pred_class = np.argmax(y_pred, axis = 1)[0]\n",
        "print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n",
        "\n",
        "fake_image = os.listdir('/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier')\n",
        "correct = 0\n",
        "total = 0\n",
        "for file_name in fake_image:\n",
        "    if file_name.endswith('jpg') or filename.endswith('png'):\n",
        "        fake_image_path = os.path.join('/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier', file_name)\n",
        "        image = prepare_image(fake_image_path)\n",
        "        image = image.reshape(-1, 128, 128, 3)\n",
        "        y_pred = model.predict(image)\n",
        "        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n",
        "        total += 1\n",
        "        if y_pred_class == 0:\n",
        "            correct += 1\n",
        "\n",
        "#print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n",
        "print(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')\n",
        "\n",
        "real_image = os.listdir('/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier')\n",
        "correct_r = 0\n",
        "total_r = 0\n",
        "for file_name in real_image:\n",
        "    if file_name.endswith('jpg') or filename.endswith('png'):\n",
        "        real_image_path = os.path.join('/content/drive/MyDrive/Dataset_Real_vs_Fake_image_BinaryClassifier', file_name)\n",
        "        image = prepare_image(real_image_path)\n",
        "        image = image.reshape(-1, 128, 128, 3)\n",
        "        y_pred = model.predict(image)\n",
        "        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n",
        "        total_r += 1\n",
        "        if y_pred_class == 1:\n",
        "            correct_r += 1\n",
        "\n",
        "#print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n",
        "correct += correct_r\n",
        "total += total_r\n",
        "print(f'Total: {total_r}, Correct: {correct_r}, Acc: {correct_r / total_r * 100.0}')\n",
        "print(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')"
      ],
      "metadata": {
        "id": "ug6rBcB7h7zZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}